# PART 7 - Deploying the application to GCP

Now we’re going to making the remaining changes to our APPLICATION. So pay attention closely!

First of all, we don’t want our research report written to a file but instead would like it delivered to us via email

- Let’s edit the params of our Crew class in the main.py file like so…
	```
	output_pydantic=NewsResults,
        output_file='report.json'
	```
    - This change tells the Manager in our Crew to output a very specific data structure when completing tasks…
    - Let’s test this out so you see what’s happening
    - We see that a “structured” JSON output has been generated by our crew
    - We can combine the flexibility of LLMs with the predictability of traditional programming by transforming this JSON output into an email body with the following code…
        - Let’s add a few more helper functions…
        - `touch helpers/is_valid_email.py`
        - `touch helpers/format_news_for_email.py`
    - PLUS update main.py & send_email.py
    - And now if we test our script again let’s see what happens…
    - `python main.py`

GREAT!!!

Next, let’s deploy this application to Google Cloud Run so we can automatically get regular reports from our Crew regardless of if our computer is turned on or off…

- In order for that to work though we’ll need to make our OPENAI_API_KEY and MAILGUN_API_KEY available to the Cloud Run applications running in our GCP project
- Here’s how we do that…
- We’re going to use another product in the GCP suite called Secret Manager
- Secret Manager is dedicated to storing sensitive data like API keys and passwords

```
gcloud services enable secretmanager.googleapis.com
gcloud services list --enabled
```

Now that this API is enabled in our GCP account, we can store sensitive data like so…

https://console.cloud.google.com/security/secret-manager?referrer=search&hl=en&project=hthaogcrj-practice

This is the command template for storing secrets in “Secret Manager”

```
echo -n "<SECRET>" | gcloud secrets create $SECRET_NAME --data-file=-
```

So this is how we would add our OPENAI_API_KEY to “Secret Manager”

```
echo -n "<YOUR_OPENAI_API_KEY>" | gcloud secrets create OPENAI_API_KEY --project $PROJECT_ID --data-file=-
```

https://console.cloud.google.com/security/secret-manager?referrer=search&hl=en&project=hthaogcrj-practice

& this is how we would add our MAILGUN_API_KEY to “Secret Manager”

```
echo -n "<YOUR_MAILGUN_API_KEY>" | gcloud secrets create MAILGUN_API_KEY --data-file=-
```

https://console.cloud.google.com/security/secret-manager?referrer=search&hl=en&project=hthaogcrj-practice

FYI, as a quick sidenote, this is the command for updating a secret to have a new value…

```
echo "YOUR_NEW_SECRET_VALUE" | gcloud secrets versions add OPENAI_API_KEY --data-file=-
```

The way we load these secret values into our Cloud Run Job is like so…

We add a new flag called `—set-secrets` to the `gcloud run jobs deploy` command of our CICD script and pass in a list of ENVIRONMENT_VARIABLES for our job by referencing their values in “Secret Manager”

--set-secrets "OPENAI_API_KEY=projects/${{ env.PROJECT_NUMBER }}/secrets/OPENAI_API_KEY:latest,MAILGUN_API_KEY=projects/${{ env.PROJECT_NUMBER }}/secrets/MAILGUN_API_KEY:latest" \

Let’s push this code to GitHub updated code to GitHub, wait for our CICD script to complete, and then trigger our Cloud Run Job to confirm we receive emails when our application runs in GCP…

OK! So we are getting an error that says our “Default compute service account” needs permissions to access our secrets

Recall that the “Default compute service account” outlines the permissions given to the Cloud Run API running in our GCP project

So make sure the PROJECT_NUMBER variable is defined in your shell and enter the following commands

gcloud secrets add-iam-policy-binding OPENAI_API_KEY \
  --member="serviceAccount:$PROJECT_NUMBER-compute@developer.gserviceaccount.com" \
  --role="roles/secretmanager.secretAccessor"

gcloud secrets add-iam-policy-binding MAILGUN_API_KEY \
  --member="serviceAccount:$PROJECT_NUMBER-compute@developer.gserviceaccount.com" \
  --role="roles/secretmanager.secretAccessor"

And after we grant our “Default compute service account” permissions to access the two 2 secrets we added to “Secret Manager”…

Let’s re-run our CICD script in GitHub

Alright that looks like it worked!

Let’s trigger our job to confirm we receive an email

`gcloud run jobs execute first-job-ever --region us-east1`

And we do indeed see an email arrive in our inbox with an A.I. generated report

Before we wrap up PART 7, let’s tweak a few  “meta” parameters of our job…

- CPU
- memory
- maxRetries
- timeoutSeconds

Because Multi-Agent systems are probabilistic, they generate a variable amount of data each time they are ran and at times I’ve seen them generate so much text that text consume all of the memory allocated to them when running in Cloud Run and crash. So to make sure our Agents have plenty of resources to be successful, let’s double the default amount of memory allocated to the container running our job and bumping the amount of retries our job is allowed to make from 3 to 5 before Cloud Run reports the job as failed to us.

--memory 1Gi
--maxRetries 5

No let’s move on…

Next up we’ll add a Monitoring Tool called AgentsOps. AgentsOps will give us easier insight into how the A.I. Agents in our application are performing compared to observing them through the GCP console. Once you get to point where you have dozens or even hundred of Agents working for you, you’re going to need a tool like AgentOps for easily monitoring them.
