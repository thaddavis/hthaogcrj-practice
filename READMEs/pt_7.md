# PART 7 - Deploying the application to GCP

Now we’re going to most fast through making the remaining changes to this PRODUCTION APPLICATION. So pay attention closely!

First of all, we don’t want our research report written to a file but instead would like it delivered to us via email

- Let’s edit the params of our Crew class in the main.py file like so…
	```
	output_pydantic=NewsResults,
        output_file='report.json'
	```
    - This change tells the Manager in our Crew to output a very specific data structure when completing tasks…
    - Let’s test this out so you see what’s happening
    - We see that a “structured” JSON output has been generated by our crew
    - Now we can combine the flexibility of LLMs with the predictability of traditional programming so transform this JSON output into an email with the following code…
        - And we’ll need to add a few more helper functions
        - `touch helpers/is_valid_email.py`
        - `touch helpers/format_news_for_email.py`
    - And now if we test our script again let’s see what happens…
    - PLUS update main.py & send_email.py
    - `python main.py`

GREAT!!!

Next, let’s deploy this application to a Google Cloud Run Job so we automatically get regular reports from our Crew regardless of if our computer is turned on or off…

- In order for that to work though we will need to make our OPENAI_API_KEY and MAILGUN_API_KEY available to any application running in our GCP project
- And here is how we do that…
- GCP offers another API/product in its suite dedicated to storing sensitive data like API_KEYS and passwords
- That product is called Secret Manager

```
gcloud services enable secretmanager.googleapis.com
gcloud services list --enabled
```

Now that this API is enabled on our GCP account, we can store sensitive data in “Secret Manager” like so…

https://console.cloud.google.com/security/secret-manager?referrer=search&hl=en&project=hthaogcrj-practice

```
echo -n "<SECRET>" | gcloud secrets create $SECRET_NAME --data-file=-
```

This is the command template so this is how we would add our OPENAI_API_KEY to “Secret Manager”

& this is how we would add our MAILGUN_API_KEY to “Secret Manager”

```
echo -n "<YOUR_OPENAI_API_KEY>" | gcloud secrets create OPENAI_API_KEY --project $PROJECT_ID --data-file=-
```

https://console.cloud.google.com/security/secret-manager?referrer=search&hl=en&project=hthaogcrj-practice

```
echo -n "<YOUR_MAILGUN_API_KEY>" | gcloud secrets create MAILGUN_API_KEY --data-file=-
```

FYI, as a quick sidenote, this is the command for how to update a secret to have a new value…

```
echo "YOUR_NEW_SECRET_VALUE" | gcloud secrets versions add OPENAI_API_KEY --data-file=-
```

And the way we load these secret values into our Cloud Run is like so…

We add a new flag called `—set-secrets` to the `gcloud run jobs deploy` command of our CICD script and pass in a list of ENVIRONMENT_VARIABLES for our job by referencing them in “Secret Manager”

--set-secrets "OPENAI_API_KEY=projects/${{ env.PROJECT_NUMBER }}/secrets/OPENAI_API_KEY:latest,MAILGUN_API_KEY=projects/${{ env.PROJECT_NUMBER }}/secrets/MAILGUN_API_KEY:latest" \

Let’s push this code to GitHub and then trigger our application in Cloud Run Jobs to confirm we still receive an email…

OK! So thing are looking good but we did get an error saying our “Default compute service account” needs permissions to access our secrets

The “Default compute service account” outlines the permissions given to the Cloud Run API running in our GCP project

So long story short is the following 2 commands will grant our “Default compute service account” permissions to access the two 2 secrets we added to “Secret Manager” 

Make sure the PROJECT_NUMBER variable is defined in your shell

gcloud secrets add-iam-policy-binding OPENAI_API_KEY \
  --member="serviceAccount:$PROJECT_NUMBER-compute@developer.gserviceaccount.com" \
  --role="roles/secretmanager.secretAccessor"

gcloud secrets add-iam-policy-binding MAILGUN_API_KEY \
  --member="serviceAccount:$PROJECT_NUMBER-compute@developer.gserviceaccount.com" \
  --role="roles/secretmanager.secretAccessor"


Now that we’ve granted these permissions let’s do one more thing that comes to my mind…

Because Multi-Agent systems spit out a lot of text, I often see them consume a lot of memory so let’s double the default amount of memory allocated to the container running our job before redeploying by adding another flag to the deploy step of our CICD script

--memory 1Gi

And now let’s re-run our CICD script in GitHub…

WHILE THE CICD PIPELINE IS IN FLIGHT, show how you might need to tweak a few  “meta” parameters (as we’ll call them) depending on the details of your job ie:

- cpu
- memory
- maxRetries
- timeoutSeconds

Alright that looks like it worked!

Let’s trigger our job to confirm we receive an email

`gcloud run jobs execute job-1 --region us-east1`

And we do indeed see an email arrive in our inbox with an A.I. generated report

Let’s move on…

Next up we’ll add a Monitoring Tool called AgentsOps. AgentsOps will give us quicker and easier insight into how our A.I. Agents are performing compared to observing them through the GCP console. 
